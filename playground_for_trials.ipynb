{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Production - a Machine Learning project playground\n",
    "\n",
    ">Author: **Andrzej Kocielski**  \n",
    "\n",
    "This is a playground notebook for testing only. The actual project notebook is [Powerproduction_ML.ipynb](https://github.com/andkoc001/Machine-Learning-and-Statistics-Project.git/Powerproduction_ML.ipynb).\n",
    "\n",
    "For more information see [README.md](https://github.com/andkoc001/Machine-Learning-and-Statistics-Project.git/README.MD).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loose notes and ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "1. There is a number of observation in the data set where produced power output is zero, regardless of the wind speed. These data points should be removed from analysis.\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Techniques\n",
    "\n",
    "- Unsupervised\n",
    "    - Clustering\n",
    "    - Dimensional reduction\n",
    "- Supervised\n",
    "    - Regression\n",
    "    - Classification\n",
    "- Reinforced Learning\n",
    "\n",
    "![image](https://miro.medium.com/max/700/1*AqNYz4M_GgfUN2ROb798yg.jpeg)\n",
    "\n",
    "Image source: [Medium.com](https://miro.medium.com/max/700/1*AqNYz4M_GgfUN2ROb798yg.jpeg)\n",
    "\n",
    "### ML algorithms\n",
    "\n",
    "- Linear regression\n",
    "- Logarithmic regression\n",
    "- Decision Tree\n",
    "- Decision Forrest\n",
    "- Random Forrest\n",
    "- t-Test\n",
    "- k nearest neighbour (kNN)\n",
    "- k-means\n",
    "- Anova (analysis of variance)\n",
    "- Support Vector Machine (SVM)\n",
    "- Principal Component Analysis (PCA)\n",
    "- Naive Bayes\n",
    "- Dimensionality Reduction Algorithms\n",
    "\n",
    "![image](https://docs.microsoft.com/en-us/azure/machine-learning/media/algorithm-cheat-sheet/machine-learning-algorithm-cheat-sheet.svg)\n",
    "Image source: [Microsoft.com](https://docs.microsoft.com/en-us/azure/machine-learning/media/algorithm-cheat-sheet/machine-learning-algorithm-cheat-sheet.svg)\n",
    "\n",
    "![image](https://miro.medium.com/max/1920/1*Lejtm0oGlOC5U0-J0JmGhg.png)\n",
    "Image source: [Medium.com](https://miro.medium.com/max/1920/1*Lejtm0oGlOC5U0-J0JmGhg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "1. Exploratory data analysis\n",
    "2. Data cleaning\n",
    "3. Data modeling (add / combine / infer additional data)\n",
    "4. Select ML techniques to be used (explain why)\n",
    "5. Do ML - analyse predictions accuracy etc. for various boundary conditions and parameters\n",
    "6. Draw a conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set is loaded from the file `powerproduction.txt`.\n",
    "df = pd.read_csv(r\"powerproduction.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting config\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, x=\"speed\", y=\"power\", s=10, height=4, aspect=2)\n",
    "plt.plot([8,8],[0,120], \"k:\")\n",
    "plt.plot([17,17],[0,120], \"k:\")\n",
    "plt.plot([24.5,24.5],[0,120], \"k:\")\n",
    "plt.text(3, 85, \"A\", size='20', color='black')\n",
    "plt.text(12, 85, \"B\", size='20', color='black')\n",
    "plt.text(20.5, 55, \"C\", size='20', color='black')\n",
    "plt.text(25.2, 55, \"F\", size='20', color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new dataframe, showing how speed values are separated from each other - difference between subsequent and current speed value\n",
    "df_sd = pd.DataFrame()\n",
    "print(df_sd)\n",
    "for index, row in df.iterrows():\n",
    "    speed_difference = df.iloc[index]['speed'] - df.iloc[index-1]['speed']\n",
    "    # print(speed_difference)\n",
    "    df_sd = df_sd.append({'speed diff': speed_difference}, ignore_index=True)\n",
    "\n",
    "df_sd = df_sd.drop(index=[0], axis=0)\n",
    "print(df_sd)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what wind speeds dominate - it appears to be more or less uniformely distributed\n",
    "plt.figure(figsize=(20,2))\n",
    "sns.distplot(df.speed, bins=100, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.distplot(df.power, bins=100, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df,\n",
    "    x=\"speed\", y=\"power\",\n",
    "    kind=\"line\", size_order=[\"T1\", \"T2\"], palette=\"pastel\",\n",
    "    height=6, aspect=3, facet_kws=dict(sharex=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression is an underfitting approximation\n",
    "plt.figure(figsize=(15,4))\n",
    "sns.regplot(data=df, x=\"speed\", y=\"power\", scatter_kws={'s':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the dataset by removing all observations where the power output is zero\n",
    "\n",
    "df_clean = df[df['power'] !=0]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = \"speed\", y = \"power\", data = df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = np.polyfit(df_clean[\"speed\"], df_clean[\"power\"], 3)\n",
    "print(ord)\n",
    "\n",
    "# y = pow(df_clean[\"speed\"],ord[0]) + pow(df_clean[\"speed\"],ord[1]) + ord[2]\n",
    "\n",
    "x = df_clean[\"speed\"]\n",
    "# plt.ylim([0, 110])\n",
    "plt.plot(x, df_clean[\"power\"], \"b.\")\n",
    "plt.plot(x, ord[0]*pow(x,3) + ord[1]*pow(x,2) + ord[2]*pow(x,1) + ord[3], \"r-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do regression on the x and y arrays using numpy.\n",
    "\n",
    "coefficients = []\n",
    "for order in range(9):\n",
    "    order = order\n",
    "    coefficients = np.polyfit(df_clean[\"speed\"], df_clean[\"power\"], order)\n",
    "    print(f\"Order {order+1}: \", end=\"\")\n",
    "    for i in range(order+1):\n",
    "        print(f\"{coefficients[i]:.6f} \", end=\"  \")\n",
    "        y = pow(df_clean[\"speed\"],i) \n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x=df_clean[\"speed\"], y=df_clean[\"power\"], test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression for cleaned dataset\n",
    "a_plot = sns.lmplot(data=df_clean, x=\"speed\", y=\"power\", order=9, height=6, aspect=2, scatter_kws={'s':1})\n",
    "\n",
    "a_plot.set(xlim=(0, 25))\n",
    "a_plot.set(ylim=(0, 120))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above polynomial appears to closely follow the pattern of the data points in the domain (wind speed in range 0-25).\n",
    "\n",
    "Let's now apply the Numpy function `polyfit()` to get the value of the coefficients that minimise the squared order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = np.polyfit(df['speed'], df['power'], 9)\n",
    "#coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the above - attempt to reproduce the plot of the polynomial with the above coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = np.polyfit(df['speed'], df['power'], 9)\n",
    "#coeff\n",
    "\n",
    "#with warnings.catch_warnings():\n",
    "#    warnings.simplefilter('ignore', np.RankWarning)    \n",
    "#    y = np.poly1d(coeff)\n",
    "    \n",
    "yp = np.poly1d(coeff)\n",
    "    \n",
    "x = np.linspace(0, 24.5, 101)\n",
    "xp = plt.plot(x, yp(x))\n",
    "\n",
    "plt.xlim(0,25)\n",
    "plt.ylim(0,120)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "plt.show()\n",
    "print(\"y = \")\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/q/51732577\n",
    "# create a shorthand for the column names\n",
    "X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "y = df.iloc[:, 1].values.reshape(-1,1)\n",
    "plt.scatter(X, y, s=2, color='blue', label=\"data\")\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "poly_reg = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "plt.plot(X, lin_reg.predict(X_poly), ls=\"--\", color = 'cyan', label='1st polynomial order')\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree = 3)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "plt.plot(X, lin_reg.predict(X_poly), ls=\"--\", color = 'green', label='2nd polynomial order')\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree = 10)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "plt.plot(X, lin_reg.predict(X_poly), ls=\"--\", color = 'red', label='9th polynomial order')\n",
    "\n",
    "\n",
    "# Visualising the Polynomial Regression results\n",
    "plt.legend(loc='best')\n",
    "# plt.xlim(0,25)\n",
    "# plt.ylim(0,120)\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/q/51732577\n",
    "# create a shorthand for the column names\n",
    "X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "y = df.iloc[:, 1].values.reshape(-1,1)\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "poly_reg_2 = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly_reg_2.fit_transform(X)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y)\n",
    "\n",
    "poly_reg_3 = PolynomialFeatures(degree = 3)\n",
    "X_poly = poly_reg_3.fit_transform(X)\n",
    "lin_reg_3 = LinearRegression()\n",
    "lin_reg_3.fit(X_poly, y)\n",
    "\n",
    "poly_reg_10 = PolynomialFeatures(degree = 10)\n",
    "X_poly = poly_reg_10.fit_transform(X)\n",
    "lin_reg_10 = LinearRegression()\n",
    "lin_reg_10.fit(X_poly, y)\n",
    "\n",
    "\n",
    "# Visualising the Polynomial Regression results\n",
    "plt.scatter(X, y, s=2, color='blue', label=\"data\")\n",
    "plt.plot(X, lin_reg_2.predict(poly_reg_2.fit_transform(X)), ls=\"--\", color = 'cyan', label='1st polynomial order')\n",
    "plt.plot(X, lin_reg_3.predict(poly_reg_3.fit_transform(X)), ls=\"--\", color = 'green', label='3rd polynomial order')\n",
    "plt.plot(X, lin_reg_9.predict(poly_reg_9.fit_transform(X)), ls=\"--\", color = 'red', label='9th polynomial order')\n",
    "plt.legend(loc='best')\n",
    "plt.xlim(0,25)\n",
    "plt.ylim(0,120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_polynomial_regression.html\n",
    "X = df.iloc[:, 0]\n",
    "y = df.iloc[:, 1].values.reshape(-1,1)\n",
    "plt.scatter(X, y, s=2, color='blue', label=\"data\")\n",
    "\n",
    "X_test = np.array([X**i for i in range(2)]).T\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_test, y)\n",
    "plt.plot(X, regr.predict(X_test), ls=\"--\", color = 'cyan', label='1st polynomial order')\n",
    "\n",
    "X_test = np.array([X**i for i in range(4)]).T\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_test, y)\n",
    "plt.plot(X, regr.predict(X_test), ls=\"--\", color = 'green', label='3rd polynomial order')\n",
    "\n",
    "X_test = np.array([X**i for i in range(10)]).T\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_test, y)\n",
    "plt.plot(X, regr.predict(X_test), ls=\"--\", color=\"red\", label='9th polynomial order')\n",
    "\n",
    "plt.xlim(0,25)\n",
    "plt.ylim(0,120)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "#help(linregress)\n",
    "linregress(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where (from the function help file):\n",
    "\n",
    "slope - Slope of the regression line.\n",
    "\n",
    "intercept - Intercept of the regression line.\n",
    "\n",
    "rvalue - Correlation coefficient.\n",
    "\n",
    "pvalue - Two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero, using Wald Test with t-distribution of the test statistic.\n",
    "\n",
    "stderr - Standard error of the estimated gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/polynomial-regression-bbe8b9d97491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# assign \"speed\" and \"power\" sets to variables X and y\n",
    "X, y = df[\"speed\"], df[\"power\"]\n",
    "\n",
    "# random_state (seed) is set for consistancy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "\n",
    "# convert the array shape and unify the lengths\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "\n",
    "# create an instance of a LinearRegression() model named lin_reg_model.\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "#Train/fit lin_reg_model on the training data.\n",
    "lin_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reschape X_test\n",
    "X_test = X_test.values.reshape(-1,1)\n",
    "\n",
    "y_predictions = lin_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "\n",
    "y_predictions = y_predictions.flatten()\n",
    "print('Mean absolute error (MAE):\\t', \n",
    "      metrics.mean_absolute_error(y_test, y_predictions), '\\t',\n",
    "      (1./len(y_test))*(sum(abs(y_test-y_predictions))))\n",
    "print('Mean squared error (MSE):\\t', \n",
    "      metrics.mean_squared_error(y_test, y_predictions), '\\t',\n",
    "      (1./len(y_test))*(sum((y_test-y_predictions)**2)))\n",
    "print('Root mean square error (RMSE):\\t', \n",
    "      metrics.mean_squared_error(y_test, y_predictions, squared=False), '\\t',\n",
    "      sqrt((1./len(y_test))*(sum((y_test-y_predictions)**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Requests\n",
    "\n",
    "The `requests` library has been now added to the other imported libraries on top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gmit.ie\"\n",
    "\n",
    "# also check https://www.httpbin.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(res))\n",
    "print(help(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.text) # print() is used for better text formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test linear regression script to be put into a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and packages - see description above\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def lin_reg(wind_speed):\n",
    "    '''\n",
    "    Doc string to be added here\n",
    "    '''\n",
    "\n",
    "    # load the data set from file\n",
    "    df_raw = pd.read_csv(r\"powerproduction.txt\")\n",
    "\n",
    "    # clean the dataset by removing all observations where the power output is zero\n",
    "    df = df_raw[df_raw['power'] !=0]\n",
    "\n",
    "    # assign \"speed\" and \"power\" sets to variables X and y\n",
    "    X, y = df[\"speed\"], df[\"power\"]\n",
    "\n",
    "    # random_state (seed) is set for consistancy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "\n",
    "    # convert the array shape and unify the lengths\n",
    "    X_train = X_train.values.reshape(-1,1)\n",
    "    y_train = y_train.values.reshape(-1,1)\n",
    "    X_test = X_test.values.reshape(-1,1)\n",
    "\n",
    "    # create an instance of a LinearRegression() model named lin_reg_model.\n",
    "    lin_reg_model = LinearRegression()\n",
    "\n",
    "    #Train/fit lin_reg_model on the training data.\n",
    "    lin_reg_model.fit(X_train, y_train)\n",
    "\n",
    "    # input wind speed for prediction\n",
    "    test = np.array([[wind_speed]])\n",
    "    # test.shape\n",
    "\n",
    "    # define prediction\n",
    "    # prediction = lin_reg_model.predict(X_test).values.reshape(-1,1)\n",
    "    prediction = lin_reg_model.predict(test)\n",
    "    return float(prediction)\n",
    "    \n",
    "lin_reg(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test poly (7th order) regression script to be put into a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 7)\n",
      "[[1.e+01 1.e+02 1.e+03 1.e+04 1.e+05 1.e+06 1.e+07]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 8 is different from 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6de451143358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6de451143358>\u001b[0m in \u001b[0;36mpoly_reg\u001b[0;34m(wind_speed)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted response: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 220\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 8 is different from 7)"
     ]
    }
   ],
   "source": [
    "# import libraries and packages - see description above\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def poly_reg(wind_speed):\n",
    "    '''\n",
    "    Doc string to be added here\n",
    "    '''\n",
    "\n",
    "    # load the data set from file\n",
    "    df_raw = pd.read_csv(r\"powerproduction.txt\")\n",
    "\n",
    "    # clean the dataset by removing all observations where the power output is zero\n",
    "    df = df_raw[df_raw['power'] !=0]\n",
    "    \n",
    "    # create a shorthand for the column names\n",
    "    X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "    y = df.iloc[:, 1]\n",
    "        \n",
    "    # develop a regression model\n",
    "    poly = PolynomialFeatures(degree = 7) # 7th polynomial order\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    # ask our model to fit the data.\n",
    "    poly_reg = LinearRegression().fit(X_poly, y)\n",
    "    # perform regression to predict the power output out of wind speed\n",
    "    y_pred = poly_reg.predict(X_poly)\n",
    "    \n",
    "    # input wind speed for prediction\n",
    "    x = np.array([[wind_speed]])\n",
    "    \n",
    "    # define prediction\n",
    "    prediction = (-5.11800967e-06*pow(x,7)) + 4.48301902e-04*pow(x,6) - 1.52309426e-02*pow(x,5) + 2.50368085e-01*pow(x,4) - 2.04365136e+00*pow(x,3) + 8.13376871e+00*pow(x,2) - 1.38470256e+01*pow(x,1) + 10.91407191*pow(x,0)\n",
    "    \n",
    "    wind_speed = np.array([wind_speed]).reshape((-1, 1))\n",
    "    print(wind_speed.shape)\n",
    "    a = PolynomialFeatures(degree=7, include_bias=False).fit_transform(wind_speed)\n",
    "    print(a.shape)\n",
    "    print(a)\n",
    "    y_pred = poly_reg.predict(a)\n",
    "    print('predicted response: ', y_pred)\n",
    "    \n",
    "    return float(prediction)\n",
    "\n",
    "\n",
    "poly_reg(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
